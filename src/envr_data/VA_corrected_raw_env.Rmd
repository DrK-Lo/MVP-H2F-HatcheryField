---
title: "VA_corrected_raw_env"
output: pdf_document
date: "2024-10-22"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

```{r packages}
library("dplyr") #Used for working with data frames
library("lubridate") #Used for time-date conversions
library("readr") #Used to read the CSV file
library("ggplot2") 
```

### Note the date of data download and source. All available data should be used for each site regardless of year. Note from the CSV file how often the site was sampled, and if there are replicates in the data. Also describe if the sampling occurred at only low tide, only high tide, or continuously.  
```{r}
#Data was downloaded on 10/01/2024
#Source - https://www.ndbc.noaa.gov/historical_data.shtml#ocean
#The site was sampled continuously every hour from 2008-2019. When compared to data from VIMS water quality monitoring in the York River, NDBC temperature data were on average 1.4°C higher than those recorded by VIMS and NDBC salinity data were on average 12.1 ppt lower than those recorded by VIMS. The data used here are the NDBC data with corrected temperature and salinity values, with temperature values 1.4°C lower and salinity values 12.1 ppt higher than the raw file. Datetime is already in POSIXct format. The corrected data were made in the VA_Envr_Data_Corrections.Rmd file.

#Create text strings with metadata information that we want to include in the final data frame. 
download_date <- ("10-01-2024")
source_description <- ("NOAA National Buoy Data Center (NDBC), Chesapeake Bay Interpretive Buoy System with values corrected based on data from VIMS Water Quality Data")
site_name <- ("VA") 
collection_type <- ("continuous")
```

### Use the file path name in your working directory or desktop, see example below. Or, import data set through the "Files" window in R studio. Store the file in a variable with the "raw_ID_Site" format. If salinity and temperature data are in separate files, read in both and store them with "_sal" or "_temp" in the variable names. 
```{r}
#The files we will be working with are from the James River, Jamestown, VA. The ID_Site for this site VA. 

#Environmental data could only be downloaded by year, so first we need to merge the yearly data sets.

#read in file
raw_VA_env <- read.csv("../../data/envr_of_origin/raw_envr_data/VA-corrected.csv")

# View how the data are stored. Note the variable names and the format and units that the data are stored in.  
summary(raw_VA_env)

#remove extra column X
raw_VA_env <- subset(raw_VA_env, select = -c(X))

#remove row with no time in the datetime column
raw_VA_env <- raw_VA_env[-c(1), ]

raw_VA_env$datetime <- as.POSIXct(raw_VA_env$datetime, "%Y-%m-%d %H:%M:%S", tz = "")

colnames(raw_VA_env) <- c("datetime", "temp", "salinity", "corrected_temp", "corrected_salinity")
```

###Standardize column and variable names. We will use "lat" for latitude in degrees, and "lon" for longitude in degrees. 

```{r}

#Store variables that we will include in the final data frame. Lat and lon data from this site: https://www.ndbc.noaa.gov/station_history.php?station=44041
lat <- 37.211
lon <- -76.787
firstyear <- 2008
finalyear <- 2019
```


### Filter any of the variables that have data points outside of normal range. We will use 0-40 as the accepted range for salinity (ppt) and temperature (C) values. Note, in the summer, salinity values can sometimes exceed 40. Check to see if there are values above 40. In this case, adjust the range or notify someone that the site has particularly high salinity values. 
```{r}
#Filter the data between the values of 0 and 40 for both salinity and temperature. 
filtered_VA_sal <- raw_VA_env %>%
    filter(between(corrected_salinity, 0, 40)) 
           
filtered_VA_env <- filtered_VA_sal %>%
    filter(between(corrected_temp, 0, 40))

# Sanity check - print the ranges to ensure values are filtered properly. We can see that the ranges for both are now in the appropriate range.  
print(summary(filtered_VA_env$corrected_salinity)) 
print(summary(filtered_VA_env$corrected_temp))

#Store our data into a variable name with just the site name. 
VA_env <- filtered_VA_env

# check for NAs
count.nas_env <- is.na(VA_env) # store our NAs in a variable
summary(count.nas_env) # we have 3131 NAs in datetime

VA_env <- na.omit(VA_env)

#re-check for NAs
count.nas_env <- is.na(VA_env) # store our NAs in a variable
summary(count.nas_env) # we have no NAs in datetime
```

#Data sets for violin plots
```{r}
#add site name and create new data frame with full envr data set
VA_env_full <- VA_env %>% 
  mutate(site_name, site_name = "VA")

#reorder columns with site_name first
VA_env_full <- VA_env_full[, c(6, 1, 2, 3, 4, 5)]

VA_temp_full <-VA_env_full[, c(1,2,3,5)]

VA_sal_full <- VA_env_full[, c(1,2,4,6)]

#save VA_env_full as csv for future analyses
write.csv(VA_temp_full, "../../data/envr_of_origin/full_temp/VA_temp_full.csv", row.names = FALSE)

write.csv(VA_sal_full, "../../data/envr_of_origin/full_sal/VA_sal_full.csv", row.names = FALSE)
```

### Visualize the salinity, temperature, and date ranges over time. This can help us see if there are any anomalies or gaps in the data and make sure the filtering was done correctly. Sanity check - do the temperature and salinity ranges look appropriate for the geography of the site (ex. near full ocean salinity for coastal sites, lower salinity for estuaries or near rivers)?

```{r salinity-plot}
salplot <- ggplot(VA_env, aes(x = datetime)) +
    geom_line(aes( y = corrected_salinity, color = "Salinity (ppt)")) +
    ylim(0,40) +
    labs(x = "Time", y = "Salinity ppt", title = "Salinity Plot for VA - James River, Jamestown Virginia") +
    scale_color_manual(values = c("Salinity (ppt)" = "blue")) +
    theme_minimal()

salplot
```


```{r temperature-plot}
tempplot <- ggplot(VA_env, aes(x = datetime)) +
    geom_line(aes(y = corrected_temp, color = "Temperature (C)")) +
    ylim(0, 40) +
    labs(x = "Time", y = "Temperature C", title = "Temperature Plot for VA - James River, Jamestown, Virginia") +
    scale_color_manual(values = c( "Temperature (C)" = "red")) +
    theme_minimal()


tempplot
```

### We need to calculate the mean, maximum, and minimum values for salinity and temperature per month and year. First make two data frames to contain each of the annual and monthly averages.
```{r}
#Calculate the mean, maximum, and minimum values for salinity and temperature for each month. 
VA_envrmonth_sal <- VA_env %>%
    mutate(year = year(datetime), month = month(datetime)) %>%
    group_by(year, month) %>%
    summarise(
      min_salinity = min(corrected_salinity),
      max_salinity = max(corrected_salinity),
      mean_salinity = mean(corrected_salinity),
      length_salinity = length(corrected_salinity))
      
VA_envrmonth_temp <- VA_env %>%
    mutate(year = year(datetime), month = month(datetime)) %>%
    group_by(year, month) %>%
    summarise(      
      min_temp = min(corrected_temp),
      max_temp = max(corrected_temp),
      mean_temp = mean(corrected_temp),
      length_temp = length(corrected_temp))
  
head(VA_envrmonth_sal)
head(VA_envrmonth_temp)


#Calculate the mean, maximum, and minimum values for salinity and temperature for each year. 
VA_envryear_sal <- VA_env %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(
      min_salinity = min(corrected_salinity),
      max_salinity = max(corrected_salinity),
      mean_salinity = mean(corrected_salinity))

VA_envryear_temp <- VA_env %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(
      min_temp = min(corrected_temp),
      max_temp = max(corrected_temp),
      mean_temp = mean(corrected_temp))

head(VA_envryear_sal)
head(VA_envryear_temp)

```
### Plot the months and years of data collection to check if there are any collection gaps in the data.
```{r timeplot - salinity}
timeplot <- ggplot(VA_envrmonth_sal, aes(x = year)) +
    geom_point(aes(y = month, color = length_salinity), size = 4) +
    labs(x = "Time", y = "Month", title = "Salinity Timeplot for VA - James River, Virginia") +
    ylim(1,12) +
    theme_minimal()

timeplot
```

### Plot the months and years of data collection to check if there are any collection gaps in the data.
```{r timeplot - temperature}
timeplot_temp <- ggplot(VA_envrmonth_temp, aes(x = year)) +
    geom_point(aes(y = month, color = length_temp), size = 4) +
    labs(x = "Time", y = "Month", title = "Temperature Timeplot for VA - James River, Jamestown, Virginia") +
    ylim(1,12) +
    theme_minimal()

timeplot_temp
```

### We can now calculate a list of variables that we will have collected for all sites. This will allow us to compare sites easily. We will calculate the number of observations from each site, the mean annual, maximum annual, and minimum annual value for all variables. 

Our list of variables includes: 

- Mean_Annual_Temperature_C: average of all available data
- Mean_max_temperature_C: average of maximums for each year
- Mean_min_temperature_C: average of minimums for each year
- Temperature_st_dev: standard deviation of all available data
- Temperature_n: total number of data points
- Temperature_years: number of years in data set

- Mean_Annual_Salinity_ppt: average of all available data
- Mean_min_Salinity_ppt: average of minimums for each year
- Mean_max_Salinity_ppt: average of maximums for each year
- Salinity_st_dev: standard deviation of all available data
- Salinity_n: total number of data points
- Salinity_years: number of years in data set

```{r}
#Calculate temperature variables. 
#Calculate temperature variables. 
Mean_Annual_Temperature_C <- mean(VA_env$corrected_temp)
Mean_max_temperature_C <- mean(VA_envryear_temp$max_temp)
Mean_min_temperature_C <- mean(VA_envryear_temp$min_temp)
Temperature_st_dev <- sd(VA_env$corrected_temp)
Temperature_n <- nrow(VA_env)
Temperature_years <- nrow(VA_envryear_temp)

#Create a data frame to store the temperature results
VA_temp <- cbind(site_name, download_date, source_description, lat, lon, firstyear, finalyear, Mean_Annual_Temperature_C, Mean_max_temperature_C, Mean_min_temperature_C, Temperature_st_dev, Temperature_n, Temperature_years, collection_type)
print(VA_temp)

# Write to a unique new CSV file
write.csv(VA_temp, "../../data/envr_of_origin/env_summarized/Temperature/VA_temperature.csv", row.names = FALSE)

```

```{r}
#Calculate the salinity variables
Mean_Annual_Salinity_ppt <- mean(VA_env$corrected_salinity)
Mean_max_Salinity_ppt <- mean(VA_envryear_sal$max_salinity)
Mean_min_Salinity_ppt <- mean(VA_envryear_sal$min_salinity)
Salinity_st_dev <- sd(VA_env$corrected_salinity)
Salinity_n <- nrow(VA_env)
Salinity_years <- nrow(VA_envryear_sal)


#Create a data frame to store the temperature results
VA_salinity <- cbind(site_name, download_date, source_description, lat, lon, firstyear, finalyear, Mean_Annual_Salinity_ppt, Mean_max_Salinity_ppt, Mean_min_Salinity_ppt, Salinity_st_dev, Salinity_n, Salinity_years, collection_type)
print(VA_salinity)

# Write to the combined file with all sites 
# Write to a unique new CSV file
write.csv(VA_salinity, "../../data/envr_of_origin/env_summarized/Salinity/VA_salinity.csv", row.names = FALSE)
```